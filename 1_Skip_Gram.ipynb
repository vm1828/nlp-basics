{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SETUP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TXT_FILE = 'data/pride_and_prejudice.txt'\n",
    "PUNCTUATION = '.;,-“’”:?—‘!()_'\n",
    "LINE_TO_EXCLUDE = r'(?i)^\\s*CHAPTER\\s*[IVXLCDM]+\\s*$'\n",
    "# SPLITTING_TO_SENTENCES_PATTERN_DIRECT_SPEECH = r'(?<!\\w\\.\\w)(?<![A-Z][a-z]\\.)(?<=\\.|\\?|\\!)(?=\\s)(?![^\"]*\"|\\')'\n",
    "# SPLITTING_TO_SENTENCES_PATTERN = r'(?<!\")(?<=[.!?…;])\\s+(?=[A-Z])'\n",
    "\n",
    "CONTEXT_WINDOW_SIZE = 2\n",
    "EPOCHS = 10\n",
    "LR = 0.1\n",
    "BATCH_SIZE = 16\n",
    "EMBEDDING_DIM = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.distributions.uniform import Uniform\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import lightning as L\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_file_url = 'https://raw.githubusercontent.com/vm1828/nlp-basics/main/data/pride_and_prejudice.txt'\n",
    "!mkdir data\n",
    "!wget --no-cache --no-check-certificate {txt_file_url} -O {TXT_FILE}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(TXT_FILE) as f:\n",
    "    text = f.read()\n",
    "    text = re.sub(LINE_TO_EXCLUDE, '', text, flags=re.MULTILINE | re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenized Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = sent_tokenize(text)\n",
    "tokenized_corpus = []\n",
    "\n",
    "for sentence in sentences:\n",
    "    tokens = []\n",
    "    for word in word_tokenize(sentence):\n",
    "        word = word.strip(PUNCTUATION)\n",
    "        if word:\n",
    "            tokens.append(word)\n",
    "    tokens.append('<EOS>')\n",
    "    tokenized_corpus.append(tokens)\n",
    "\n",
    "print(tokenized_corpus[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexed Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build vocabulary\n",
    "WORD2IDX = {word: idx for idx, word in enumerate(set(sum(tokenized_corpus, [])))}\n",
    "IDX2WORD = {idx: word for word, idx in WORD2IDX.items()}\n",
    "VOCAB_SIZE = len(WORD2IDX)\n",
    "# Convert tokenized corpus to indexed corpus\n",
    "indexed_corpus = [[WORD2IDX[word] for word in sentence] for sentence in tokenized_corpus]\n",
    "\n",
    "print(indexed_corpus[0])\n",
    "print(len(indexed_corpus))\n",
    "print(VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skip-Gram Pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_skipgrams(indexed_corpus, window_size=CONTEXT_WINDOW_SIZE): \n",
    "    data = []\n",
    "    for sentence in indexed_corpus:\n",
    "        for i, target in enumerate(sentence):\n",
    "            window = range(max(0, i-window_size), min(len(sentence), i+window_size+1))\n",
    "            context = [sentence[j] for j in window if j!=i]\n",
    "            for ctx in context:\n",
    "                data.append((target, ctx)) # pair every word with each word in the context\n",
    "    return data\n",
    "\n",
    "skipgram_pairs = generate_skipgrams(indexed_corpus)\n",
    "print(skipgram_pairs[0])\n",
    "print(len(skipgram_pairs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.LongTensor([pair[0] for pair in skipgram_pairs])  # target words\n",
    "y_train = torch.LongTensor([pair[1] for pair in skipgram_pairs])  # context words\n",
    "# nn.Embedding and nn.CrossEntropyLoss require torch.int64 (LongTensor) inputs for indexing and categorical targets.\n",
    "\n",
    "dataset = TensorDataset(X_train, y_train)\n",
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "INPUT_DIM = VOCAB_SIZE\n",
    "\n",
    "class SkipGramModelFromScratch(L.LightningModule):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        L.seed_everything(seed=42)\n",
    "        self.input_to_hidden = nn.Linear(in_features=len(dataset), out_features=EMBEDDING_DIM, bias=False)\n",
    "        self.hidden_to_output = nn.Linear(in_features=2, out_features=4, bias=False)\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, input):\n",
    "        hidden = self.input_to_hidden(input)\n",
    "        # Then we pass \"hidden\" to the weights we created with nn.Linear() between the hidden layer and the output.\n",
    "        output_values = self.hidden_to_output(hidden)\n",
    "        return(output_values)\n",
    "\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return Adam(self.parameters(), lr=LR)\n",
    "\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        input_i, label_i = batch\n",
    "        output_i = self.forward(input_i)\n",
    "        loss = self.loss(output_i, label_i)\n",
    "        \n",
    "        self.log(\"train_loss\", loss)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nn.Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkipGramModelEmbedding(L.LightningModule):\n",
    "\n",
    "    def __init__(self, vocabulary_size, embedding_size):\n",
    "        super().__init__()\n",
    "        self.embeddings = nn.Embedding(vocabulary_size, embedding_size)\n",
    "        self.linear = nn.Linear(embedding_size, vocabulary_size)\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, context_word):\n",
    "        embedding = self.embeddings(context_word)\n",
    "        output = self.linear(embedding)\n",
    "        return output\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return Adam(self.parameters(), lr=LR)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        input_i, label_i = batch\n",
    "        output_i = self.forward(input_i)\n",
    "        loss = self.loss(output_i, label_i)\n",
    "\n",
    "        self.log(\"train_loss\", loss)\n",
    "        \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelEmbedding = SkipGramModelEmbedding(VOCAB_SIZE, EMBEDDING_DIM)\n",
    "trainer = L.Trainer(max_epochs=EPOCHS)\n",
    "trainer.fit(modelEmbedding, train_dataloaders=dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEMO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_words_embedding(model):\n",
    "  \n",
    "  words = [\n",
    "    'Elizabeth', 'Darcy', 'Bingley', 'Lydia', 'Jane', 'Collins', 'Pemberley', \n",
    "    'Meryton', 'Lady', 'Wickham', 'marriage', 'love', 'prejudice', 'fortune', \n",
    "    'accomplished', 'pride', 'sense', 'character', 'family', 'society',\n",
    "    'husband', 'wife', 'man', 'woman', 'summer', 'spring', 'winter'\n",
    "  ]\n",
    "  \n",
    "  indices = [WORD2IDX[word] for word in words]\n",
    "  embeddings = model.embeddings.weight.data[indices]\n",
    "\n",
    "  tsne = TSNE(n_components=2, perplexity=20, random_state=42) # 2d t-SNE\n",
    "  embeddings_2d = tsne.fit_transform(embeddings)\n",
    "\n",
    "  colors = sns.husl_palette(n_colors = len(words))\n",
    "  plt.figure(figsize=(10, 10))\n",
    "  for i, word in enumerate(words):\n",
    "    plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1],c=colors)\n",
    "    plt.annotate(word, xy=(embeddings_2d[i, 0], embeddings_2d[i, 1]))\n",
    "  \n",
    "  plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_words_embedding(modelEmbedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
