{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "40ce84c3",
            "metadata": {},
            "source": [
                "# SETUP"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "093fa485",
            "metadata": {},
            "source": [
                "## Import"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "7707d486",
            "metadata": {},
            "outputs": [],
            "source": [
                "import re\n",
                "import json\n",
                "import requests\n",
                "from bs4 import BeautifulSoup\n",
                "\n",
                "from shared.constants import *\n",
                "from shared.corpus import Corpus\n",
                "\n",
                "import spacy"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "0b16abe4",
            "metadata": {},
            "outputs": [],
            "source": [
                "# # Get characters\n",
                "\n",
                "# url = \"https://pemberley.com/janeinfo/ppdrmtis.html\"\n",
                "# res = requests.get(url)\n",
                "# soup = BeautifulSoup(res.content, \"html.parser\")\n",
                "\n",
                "# character_names = []\n",
                "# target_h2 = soup.find(\"h2\", string=\"Brief, Organized Listing of Characters\")\n",
                "# target_ul = target_h2.find_next(\"ul\")\n",
                "# for a in target_ul.find_all(\"a\"):\n",
                "#     name = a.get_text(strip=True).replace('\\n', ' ')\n",
                "#     if name:\n",
                "#         character_names.append(name)\n",
                "\n",
                "# print(character_names)\n",
                "# with open(JSON_CHARACTERS_PNP, \"w\", encoding=\"utf-8\") as f:\n",
                "#     json.dump(character_names, f, indent=4)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "8664b4e3",
            "metadata": {},
            "source": [
                "# Rule-Based NER (Gazetteer Method)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "f558c621",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "['Mr. Bennet', 'Mrs. Bennet', 'Jane', 'Elizabeth', 'Mary', 'Kitty', 'Lydia', 'Bingley', 'Louisa Hurst', 'Caroline', 'Mr. Collins', 'Old Mr. Darcy', 'Lady Anne Darcy', 'Darcy', 'Georgiana Darcy', 'Lady Catherine', 'Anne de Bourgh', 'Colonel Fitzwilliam', 'Mr. Gardiner', 'Mrs. Gardiner', 'Sir William', 'Lady Lucas', 'Charlotte', 'Maria', 'Old Mr. Wickham', 'Wickham', 'Mrs. Annesley', 'Captain Carter', 'Mr. Chamberlayne', 'Dawson', 'Mr. Denny', 'Colonel Forster', 'William Goulding', 'Miss Grantley', 'Haggerston', 'The Harringtons', 'Mrs. Hill', 'Mr. Hurst', 'Mrs. Jenkinson', 'Mr. Jones', 'Miss Mary King', 'Mrs. Long', 'Lady Metcalfe', 'Mr. Morris', 'Mrs. Nicholls', 'Mr. Philips', 'Miss Pope', 'Mr. Pratt', 'Mrs. Reynolds', 'Mr. Robinson', 'Mr. Stone', 'Miss Watson', 'The Miss Webbs', 'Mrs. Younge']\n",
                        "['Forster', 'Catherine', 'Watson', 'Pratt', 'Jones', 'Goulding', 'Harringtons', 'Metcalfe', 'Fitzwilliam', 'Robinson', 'Lydia', 'Webbs', 'Collins', 'Reynolds', 'Georgiana', 'Maria', 'King', 'Hill', 'Long', 'Lucas', 'Hurst', 'Caroline', 'Mary', 'Kitty', 'Bingley', 'William', 'Denny', 'Wickham', 'Haggerston', 'Philips', 'Bourgh', 'Elizabeth', 'Pope', 'Annesley', 'Chamberlayne', 'Charlotte', 'Nicholls', 'Grantley', 'Jenkinson', 'Jane', 'Younge', 'Morris', 'Gardiner', 'Darcy', 'Stone', 'Dawson', 'Louisa', 'Anne', 'Carter', 'Bennet']\n"
                    ]
                }
            ],
            "source": [
                "# Load data\n",
                "with open(TXT_PNP, \"r\", encoding=\"utf-8\") as f:\n",
                "    text = f.read().strip()\n",
                "    text = re.split(PATTERN_CHAPTER_LINE, text)[1:6]\n",
                "\n",
                "with open(JSON_CHARACTERS_PNP, \"r\", encoding=\"utf-8\") as f:\n",
                "    characters = json.load(f)\n",
                "    names = set()\n",
                "    for character in characters:\n",
                "        names.update(\n",
                "            [\n",
                "                i for i in character.split() \n",
                "                if not i in ['Mr.', 'The', 'Mrs.', 'Miss', 'Old', 'Lady', 'de', 'Sir', 'Captain', 'Colonel']\n",
                "            ]\n",
                "        )\n",
                "    names = list(names)\n",
                "\n",
                "print(characters)\n",
                "print(names)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "c5a3dade",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "\n",
                        "Chapter 1:\n",
                        "Mrs Long, Mr Morris, Mr Bennet, Bingley, Sir William, Lydia, Mr Bingley, Jane, Lady Lucas\n",
                        "\n",
                        "\n",
                        "Chapter 2:\n",
                        "Mrs Long, Mrs Bennet, Elizabeth, Now Kitty, Mr Bennet, Kitty, Mary, Lydia, Mr Bingley, While Mary\n",
                        "\n",
                        "\n",
                        "Chapter 3:\n",
                        "Catherine, Elizabeth Bennet, Mr Darcy, Lydia, Miss King, Mr Hurst, Maria, Miss Bennet, Mary, Bingley, Mrs Hurst, Miss Lucas, Elizabeth, Sir William, Mr Bingley, Jane, Lady Lucas, Mrs Bennet, Miss Bingley, Maria Lucas, Mr Bennet, Come Darcy\n",
                        "\n",
                        "\n",
                        "Chapter 4:\n",
                        "Elizabeth, When Jane, Miss Bingley, Miss Bennet, Bingley, Darcy, Mr Bingley, Mrs Hurst\n",
                        "\n",
                        "\n",
                        "Chapter 5:\n",
                        "Mrs Long, Mrs Bennet, Miss Lucas, Elizabeth, Mr Robinson, Miss Bingley, Miss Bennet, Lucas, Charlotte, Mr Darcy, Mary, William Lucas, Sir William, Jane, Lady Lucas\n"
                    ]
                }
            ],
            "source": [
                "# Characters by Chapter\n",
                "for n_chapter, chapter in enumerate(text, start=1):\n",
                "    print(f'\\n\\nChapter {n_chapter}:')\n",
                "    chapter = chapter.strip().replace('\\n', ' ').translate(str.maketrans('', '', PUNCTUATION))\n",
                "    words = chapter.split() # NOTE: Mr and Mrs will be split\n",
                "\n",
                "    chapter_names = set()\n",
                "    for n, word in enumerate(words):\n",
                "        if word in names:\n",
                "            if (words[n-2] == 'Old') or (words[n-1] == 'de'):\n",
                "                chapter_names.add(' '.join(words[n-2:n+1])) # Handle 3-word names\n",
                "            elif words[n-1][0].isupper():\n",
                "                chapter_names.add(' '.join(words[n-1:n+1])) # Handle 2-word names\n",
                "            else:\n",
                "                chapter_names.add(word)\n",
                "    print(', '.join(chapter_names))"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "8b7c17a2",
            "metadata": {},
            "source": [
                "# NER with SpaCy"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "353dffb6",
            "metadata": {},
            "source": [
                "## Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "e8aa811c",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "'Mr. and Mrs. Dursley, of number four, Privet Drive, were proud to say that they were perfectly norma'"
                        ]
                    },
                    "execution_count": 5,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# Data\n",
                "hp_corpus = Corpus(DIR_HP)\n",
                "chapter1 = hp_corpus.books[0].chapters[0].text\n",
                "chapter1[:100]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "c83056b6",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "['Hannah Abbott', 'Ludo Bagman', 'Bathilda Bagshot', 'Katie Bell', 'Cuthbert Binns', 'Phineas Nigellus Black', 'Sirius Black', 'Regulus Black', 'Amelia Bones', 'Edgar Bones']\n"
                    ]
                }
            ],
            "source": [
                "# url = \"https://en.wikipedia.org/wiki/List_of_Harry_Potter_characters\"\n",
                "# res = requests.get(url)\n",
                "# soup = BeautifulSoup(res.content, \"html.parser\")\n",
                "\n",
                "# characters = []\n",
                "# divs = soup.find_all(\"div\", class_=\"mw-heading mw-heading3\")\n",
                "# for div in divs:\n",
                "#     ul = div.find_next(\"ul\")\n",
                "#     for li in ul.find_all(\"li\"):\n",
                "#             text = li.get_text(strip=True)\n",
                "#             name = re.search(r\"^(.*?)â€“\", text).group(1).replace(' and ', ',').translate(str.maketrans('()', ',,'))\n",
                "#             if ',' in name:\n",
                "#                 split_name = [part.strip() for part in name.split(',') if part.strip()]\n",
                "#                 last_name = split_name[0]\n",
                "\n",
                "#                 # Case: <last_name>, <name 1>, <name2>, ...\n",
                "#                 if len(split_name[1:]) > 1:\n",
                "#                     for first_name in split_name[1:]:\n",
                "#                         characters.append(f'{first_name.strip()} {last_name.strip()}')\n",
                "#                 # Case: <last_name>, <first_name>\n",
                "#                 else:\n",
                "#                     characters.append(f'{split_name[1].strip()} {last_name.strip()}')\n",
                "#             else:\n",
                "#                 # Case: <name>\n",
                "#                 characters.append(name.strip())\n",
                "\n",
                "# print(characters[:10])\n",
                "# with open(JSON_CHARACTERS_HP, \"w\", encoding=\"utf-8\") as f:\n",
                "#     json.dump(characters, f, indent=4)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "id": "0edc4c26",
            "metadata": {},
            "outputs": [],
            "source": [
                "nlp = spacy.load('en_core_web_lg')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "id": "2f3503be",
            "metadata": {},
            "outputs": [],
            "source": [
                "doc = nlp(chapter1)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "id": "1f2cf7b0",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Dursley        PERSON    \n",
                        "number four    CARDINAL  \n",
                        "Privet Drive   PERSON    \n",
                        "Grunnings      ORG       \n",
                        "Dursleys       NORP      \n",
                        "Dudley         PERSON    \n",
                        "Potters        ORG       \n",
                        "Potter         PERSON    \n",
                        "several years  DATE      \n",
                        "Tuesday        DATE      \n"
                    ]
                }
            ],
            "source": [
                "unique_ents = list({ent.text: ent for ent in doc.ents}.values())\n",
                "for ent in unique_ents[:10]:\n",
                "    print(f'{ent.text:<15}{ent.label_:<10}')"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "5fc7a6f8",
            "metadata": {},
            "source": [
                "We need to customize the model to make NER for the HP corpus better"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "12155170",
            "metadata": {},
            "source": [
                "## EntityRuler"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "b37b446b",
            "metadata": {},
            "source": [
                "Using EntityRuler we can generate rule-based NER with SpaCy.  \n",
                "This approach can be used to generate train datasets."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
